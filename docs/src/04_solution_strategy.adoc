ifndef::imagesdir[:imagesdir: ../images]

[[section-solution-strategy]]
== Solution Strategy

In this section we will describe the approach taken to develop the system from a high-level perspective. This includes the technologies used, the architecture of the system and the most important organizational decisions.

=== Technologies

The following technologies are used in our project:

* *NodeJS*: To build our backend, we will use this technology due to its simplicity and its ability to create scalable and efficient servers. This technology is not so familiar to the team but as it is widely used we think we won't have many issues as there are plenty of resources available (documentation, GitHub repos, StackOverflow...).
* *Jest*: To test the system, we will use this technology due to its simplicity and its ability to create scalable and efficient tests. Similarly to NodeJS, this is not a technology the team is familiared with, but, for the same reasons exposed before, we don't think we will have many issues.
* *MongoDB*: To store the data, we will use this technology due to its flexibility and scalability. Furthermore, this technology is recommended to use combined with NodeJS as they perform quite well together (therefore avoiding the pitfall of performance that is typically associated with the use of NoSQL databases over SQL ones). The team is not so used to work with NoSQL databases, but we think that it will be a good opportunity to learn something new.
** *MongoDB Compass*: For being able to visualize the data stored in MongoDB, we will use this tool. It is a GUI for MongoDB that allows us to see the data stored in the database and to perform queries on it. This tool is very useful for debugging and for understanding how the data is stored in the database. Moreover, it allows us to handle incorrect data that we may introduce during development in a friendly way.
* *React*: To build the web application's UI, we will use this technology due to its simplicity and its ability to create reusable components. It has also been chosen as it has a relatively gentle learning curve (as we will be learning while building).
* *Docker*: To deploy the system, we will use this technology due to its portability and reliability.
* *Git & GitHub*: For version control and collaboration, we will use Git and GitHub. These tools will enable the team to collaborate efficiently and keep track of changes, issues and documentation.
* *GitHub Actions*: We will use this tool to automate the CI/CD process. This will help the team to keep the codebase clean and maintainable. We will use it to run tests, build the project and deploy it automatically when changes are made to the main branch. There will be two different workflows:
** *CI*: This workflow will be triggered when changes are made to the main branch. It will run the tests and build the project. If everything goes well, it will deploy the project to the production environment.
** *CD*: This workflow will be triggered when we choose to deploy in GitHub. It will run the tests and build the project. If everything goes well, it will deploy the project to the production environment.
* *SonarQube*: For static code analysis, we will use SonarQube. This tool will help the team to keep the codebase clean and maintainable. The usage of this tool will provide us reports about the code quality and security. It will be integrated into the CI/CD process, so that it will run automatically when changes are made to the main branch. It will also be used to generate reports about the code quality and security.
* *QWen2.5 (7B parameters)*: To add the LLM functionality to the system, we will use this model. This way we may apply to the Empathy contest if we decided to do so. That is the main reason to use this model because we felt that using others like Gemini or DeepSeek would probably provide better results, but we would not be able to enroll our project in the contest.
* *Azure*: To deploy the system, we will use Azure due to its scalability and reliability. We will use a VM stored in Azure to deploy the system and make it accessible. We could have used any other cloud provider, but we decided to use Azure because it was the one shown in the course. Moreover, we could have used a local server, but that would demand to have a machine running 24/7 and we would have to take care of some security issues that using a cloud provided are not so relevant.
* *Postman*: To manually test the APIs we expose, we will use this tool. It is a very useful tool for testing APIs and it allows us to test the APIs without having to build the whole system. It is also very useful for debugging and for understanding how the APIs work. It will be useful also to build automated tests for the APIs, provided that the tests done in one of them should not depend on ohter APIs. We may use this tool to see exactly what each API expects and returns to build mocks for the tests.
* *Swagger*: To document the main API in the system (the one exposed by the Gateway-Service), we will use this software. It is a well known tool for documenting APIs and it allows to generate documentation in a semi-automatic way. In our case, we will use a YAML file to describe the documentation and then we will use Swagger to generate it. We will try to keep the documentation as close as possible to the OpenAPI standard (as requested in the course).
* *Grafana and Prometheus*: To provide live handeling of the status of the application, we have used these two technologies. The main reason to chooose them is that a lesson was provided about them and that we only needed to minimally configure them in our project to make them work.
* *JMeter*: To perform the load tests we choose to use JMeter over the proposed technology (Gatling) because JMeter is open-source and this way we would not need to worry about the usage of the tokens.

=== Architecture

The system will be divided into several components, each one will have theit own responsibility. The idea is to follow a microservices architecture, where each component is responsible for a specific task. This way we can scale the system more easily and we can have a more organized codebase. Also, we may be able to work in parallel on different components.

The specific components are:

* *WebApp*: This component will be responsible for the user interface. It will be built using React and will be responsible for displaying the information to the user and for sending the user's input to the backend services.
* *Gateway-Service*: This component will be responsible for routing the requests to the correct service. It will be built using NodeJS and will be responsible for handling the requests from the WebApp and sending them to the correct service.
* *Users*: This component will be responsible for managing the users. It will be built using NodeJS and will be responsible for handling the user's information and authentication. Within this service, there are several subcomponents:
** *User-Service*: This sub-service will be used to handle users within the database.
** *Auth-Service*: This sub-service will be used to handle the authentication of the users.
** *Game-Service*: This sub-service will be used to store the games that the users play.
** *LeaderBoard-Service*: This sub-service will be used to retrieve information about users and games to be displayed ordered (for now by the total score obtained).
* *Questions-Service*: This component will be responsible for retrieving the questions from Wikidata and storing them in its database. It will be built using NodeJS and will be responsible for handling the requests from the Gateway-Service and sending them to Wikidata.
* *LLM-Service*: This component will be responsible of any interaction the system performs with the LLM model. It will be built using NodeJS and will be responsible for handling the requests from the Gateway-Service and sending them to the LLM model.
* *Scheduling-Service*: This component will be in charge of the timing of when the retrieval of questions from Wikidata is done. The current implementation is that every day at 1 AM the questions will be erased and new ones will be retrieved. This service will be built using NodeJS.

We will try to follow the microservices architecture as much as possible, but it is quite possible that some of the 'microservices' will be using the same database due to information sharing. However, we will try to keep the services as independent as possible.

[#organizational_decisions]
=== Organizational Decisions

All decisions will be recorded at the https://github.com/Arquisoft/wichat_en2a/wiki/Team-Decisions[decision's section] of the Wiki of the project. We have decided to do it in such a way so that we do not need to deploy the documentation all the times we record a decision.